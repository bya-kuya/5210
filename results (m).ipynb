{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "43cea27a",
   "metadata": {},
   "source": [
    "# Dataset Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d6354a0",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './data/left_dataset.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m left_dataset_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./data/left_dataset.csv\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      4\u001b[0m right_dataset_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./data/right_dataset.csv\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 6\u001b[0m left_dataset \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(left_dataset_path)\n\u001b[1;32m      7\u001b[0m right_dataset \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(right_dataset_path)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:912\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    899\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    900\u001b[0m     dialect,\n\u001b[1;32m    901\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    908\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m    909\u001b[0m )\n\u001b[1;32m    910\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 912\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:577\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    574\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    576\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 577\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    579\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    580\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1407\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1404\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1406\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1407\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1661\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1659\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1660\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1661\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[1;32m   1662\u001b[0m     f,\n\u001b[1;32m   1663\u001b[0m     mode,\n\u001b[1;32m   1664\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1665\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1666\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[1;32m   1667\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[1;32m   1668\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1669\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1670\u001b[0m )\n\u001b[1;32m   1671\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1672\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/common.py:859\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    854\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    855\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    856\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    857\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    858\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 859\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[1;32m    860\u001b[0m             handle,\n\u001b[1;32m    861\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[1;32m    862\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[1;32m    863\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[1;32m    864\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    865\u001b[0m         )\n\u001b[1;32m    866\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    867\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    868\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './data/left_dataset.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# Load the datasets\n",
    "left_dataset_path = './data/left_dataset.csv'\n",
    "right_dataset_path = './data/right_dataset.csv'\n",
    "\n",
    "left_dataset = pd.read_csv(left_dataset_path)\n",
    "right_dataset = pd.read_csv(right_dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "36d022a2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entity_id</th>\n",
       "      <th>name</th>\n",
       "      <th>address</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>postal_code</th>\n",
       "      <th>categories</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>The UPS Store</td>\n",
       "      <td>87 Grasso Plaza Shopping Center</td>\n",
       "      <td>Affton</td>\n",
       "      <td>MO</td>\n",
       "      <td>63123.0</td>\n",
       "      <td>Shipping Centers, Local Services, Notaries, Ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>St Honore Pastries</td>\n",
       "      <td>935 Race St</td>\n",
       "      <td>Philadelphia</td>\n",
       "      <td>PA</td>\n",
       "      <td>19107.0</td>\n",
       "      <td>Restaurants, Food, Bubble Tea, Coffee &amp; Tea, B...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Perkiomen Valley Brewery</td>\n",
       "      <td>101 Walnut St</td>\n",
       "      <td>Green Lane</td>\n",
       "      <td>PA</td>\n",
       "      <td>18054.0</td>\n",
       "      <td>Brewpubs, Breweries, Food</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Sonic Drive-In</td>\n",
       "      <td>615 S Main St</td>\n",
       "      <td>Ashland City</td>\n",
       "      <td>TN</td>\n",
       "      <td>37015.0</td>\n",
       "      <td>Burgers, Fast Food, Sandwiches, Food, Ice Crea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Famous Footwear</td>\n",
       "      <td>8522 Eager Road, Dierbergs Brentwood Point</td>\n",
       "      <td>Brentwood</td>\n",
       "      <td>MO</td>\n",
       "      <td>63144.0</td>\n",
       "      <td>Sporting Goods, Fashion, Shoe Stores, Shopping...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   entity_id                      name  \\\n",
       "0          1             The UPS Store   \n",
       "1          2        St Honore Pastries   \n",
       "2          3  Perkiomen Valley Brewery   \n",
       "3          4            Sonic Drive-In   \n",
       "4          5           Famous Footwear   \n",
       "\n",
       "                                      address          city state  \\\n",
       "0             87 Grasso Plaza Shopping Center        Affton    MO   \n",
       "1                                 935 Race St  Philadelphia    PA   \n",
       "2                               101 Walnut St    Green Lane    PA   \n",
       "3                               615 S Main St  Ashland City    TN   \n",
       "4  8522 Eager Road, Dierbergs Brentwood Point     Brentwood    MO   \n",
       "\n",
       "   postal_code                                         categories  \n",
       "0      63123.0  Shipping Centers, Local Services, Notaries, Ma...  \n",
       "1      19107.0  Restaurants, Food, Bubble Tea, Coffee & Tea, B...  \n",
       "2      18054.0                          Brewpubs, Breweries, Food  \n",
       "3      37015.0  Burgers, Fast Food, Sandwiches, Food, Ice Crea...  \n",
       "4      63144.0  Sporting Goods, Fashion, Shoe Stores, Shopping...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "left_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c21d650d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>name</th>\n",
       "      <th>address</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>zip_code</th>\n",
       "      <th>size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>SOURINI PAINTING INC.</td>\n",
       "      <td>12800 44th St N</td>\n",
       "      <td>Clearwater</td>\n",
       "      <td>FL</td>\n",
       "      <td>33762-4726</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>WOLFF DOLLA BILL LLC</td>\n",
       "      <td>1905 E 19th Ave</td>\n",
       "      <td>Tampa</td>\n",
       "      <td>FL</td>\n",
       "      <td>33605-2700</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>COMPREHENSIVE SURGERY CENTER, LLC</td>\n",
       "      <td>1988 GULF TO BAY BLVD, Ste 1</td>\n",
       "      <td>CLEARWATER</td>\n",
       "      <td>FL</td>\n",
       "      <td>33765-3550</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>FRANK &amp; ADAM APPAREL LLC</td>\n",
       "      <td>13640 Wright Cir</td>\n",
       "      <td>Tampa</td>\n",
       "      <td>FL</td>\n",
       "      <td>33626-3030</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>MORENO PLUS TRANSPORT INC</td>\n",
       "      <td>8608 Huron Court unite 58</td>\n",
       "      <td>Tampa</td>\n",
       "      <td>FL</td>\n",
       "      <td>33614</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   business_id                               name  \\\n",
       "0            1              SOURINI PAINTING INC.   \n",
       "1            2               WOLFF DOLLA BILL LLC   \n",
       "2            3  COMPREHENSIVE SURGERY CENTER, LLC   \n",
       "3            4           FRANK & ADAM APPAREL LLC   \n",
       "4            5          MORENO PLUS TRANSPORT INC   \n",
       "\n",
       "                        address        city state    zip_code  size  \n",
       "0               12800 44th St N  Clearwater    FL  33762-4726  11.0  \n",
       "1               1905 E 19th Ave       Tampa    FL  33605-2700   8.0  \n",
       "2  1988 GULF TO BAY BLVD, Ste 1  CLEARWATER    FL  33765-3550   8.0  \n",
       "3              13640 Wright Cir       Tampa    FL  33626-3030  12.0  \n",
       "4     8608 Huron Court unite 58       Tampa    FL       33614   8.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "right_dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c78ff35b",
   "metadata": {},
   "source": [
    "## Results from different packages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a3e9207",
   "metadata": {},
   "source": [
    "### Rapidfuzz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f1cfce69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary functions from the module created by Leo Zhou\n",
    "from src.rapidfuzz import clean_text, standardize_zip_code, clean_address, create_enhanced_block_keys, fuzzy_match_with_rapidfuzz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d523d5be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dataset in different name to avoid duplication and conflicts\n",
    "left_df = pd.read_csv(left_dataset_path)\n",
    "right_df = pd.read_csv(right_dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6e20397d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply cleaning steps\n",
    "left_df['name'] = left_df['name'].apply(clean_text)\n",
    "left_df['state'] = left_df['state'].apply(clean_text)\n",
    "left_df['city'] = left_df['city'].apply(clean_text)\n",
    "right_df['name'] = right_df['name'].apply(clean_text)\n",
    "right_df['state'] = right_df['state'].apply(clean_text)\n",
    "right_df['city'] = right_df['city'].apply(clean_text)\n",
    "\n",
    "# Apply zip code standardizing\n",
    "right_df['zip_code'] = right_df['zip_code'].apply(standardize_zip_code)\n",
    "left_df['postal_code'] = left_df['postal_code'].apply(standardize_zip_code)\n",
    "\n",
    "# Apply the address cleaning function to the DataFrame columns\n",
    "left_df['address'] = left_df['address'].apply(clean_address)\n",
    "right_df['address'] = right_df['address'].apply(clean_address)\n",
    "\n",
    "# Extra Step to drop unwanted columns and standardize column names\n",
    "left_df.drop(columns=['categories'], inplace=True)\n",
    "right_df.drop(columns=['size'], inplace=True)\n",
    "\n",
    "left_df.rename(columns={'postal_code': 'zip_code'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2c4d48f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply enhanced blocking\n",
    "left_df = create_enhanced_block_keys(left_df)\n",
    "right_df = create_enhanced_block_keys(right_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fdf5248d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating column for rapidfuzz application\n",
    "left_df['combined'] = left_df['name'].apply(clean_text) + \" \" + left_df['address'].apply(clean_address)\n",
    "right_df['combined'] = right_df['name'].apply(clean_text) + \" \" + right_df['address'].apply(clean_address)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "381eac9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rapidfuzz import process, fuzz\n",
    "\n",
    "# Execute fuzzy matching\n",
    "matched_results = fuzzy_match_with_rapidfuzz(left_df, right_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f7652355",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       left_dataset  right_dataset  confidence_score\n",
      "0              8703          20197         85.500000\n",
      "1             19631          20197         85.500000\n",
      "2             73038          20197         85.500000\n",
      "3             85862          20197         85.500000\n",
      "4               903          63344         85.500000\n",
      "...             ...            ...               ...\n",
      "47616          1115          23915         95.000000\n",
      "47617         17529           4609         85.500000\n",
      "47618         59493          22503         95.238095\n",
      "47619         92447          12152         96.721311\n",
      "47620         61857          38198         85.500000\n",
      "\n",
      "[47621 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "print(matched_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1996a6a0",
   "metadata": {},
   "source": [
    "### recordlinkage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "85709c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import recordlinkage\n",
    "from recordlinkage.preprocessing import clean, phonetic\n",
    "from src.recordlinkage import preprocess_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "78a31b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "left = pd.read_csv(left_dataset_path)\n",
    "right = pd.read_csv(right_dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a5b140bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "left = preprocess_data(left)\n",
    "right = preprocess_data(right)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "feea39d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "left.rename(columns={'postal_code': 'zip_code'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9d33b35a",
   "metadata": {},
   "outputs": [],
   "source": [
    "string_columns = ['address', 'city', 'state', 'zip_code']\n",
    "for column in string_columns:\n",
    "    left[column] = left[column].astype(str)\n",
    "    right[column] = right[column].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3bdc856c",
   "metadata": {},
   "outputs": [],
   "source": [
    "left['address'] = left['address'].str.cat(left[['city', 'state', 'zip_code']], sep=' ')\n",
    "right['address'] = right['address'].str.cat(right[['city', 'state', 'zip_code']], sep=' ')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bc5393c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_keep_left = ['entity_id', 'name', 'address']\n",
    "columns_to_keep_right = ['business_id', 'name', 'address']\n",
    "left_common = left[columns_to_keep_left]\n",
    "right_common = right[columns_to_keep_right]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e696aa13",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Johnz\\AppData\\Local\\Temp\\ipykernel_101080\\1235932494.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  left_common['block_key'] = left_common['name'].str[:5]\n",
      "C:\\Users\\Johnz\\AppData\\Local\\Temp\\ipykernel_101080\\1235932494.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  right_common['block_key'] = right_common['name'].str[:5]\n"
     ]
    }
   ],
   "source": [
    "left_common['block_key'] = left_common['name'].str[:5]\n",
    "right_common['block_key'] = right_common['name'].str[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6a57eca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "indexer = recordlinkage.Index()\n",
    "indexer.block('block_key')\n",
    "candidate_links = indexer.index(left_common, right_common)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "47ab3fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "comparer = recordlinkage.Compare()\n",
    "comparer.string('name', 'name', method='jarowinkler', label='name_similarity')\n",
    "comparer.string('address', 'address', method='jarowinkler', label='address_similarity')\n",
    "features = comparer.compute(candidate_links, left_common, right_common)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9e31c8fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "features['confidence_score'] = features.mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b4a48659",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.8\n",
    "matches = features[features['confidence_score'] >= threshold]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "81f15719",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Johnz\\AppData\\Local\\Temp\\ipykernel_101080\\891293443.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  matches['entity_id'] = matches.index.get_level_values(0)\n",
      "C:\\Users\\Johnz\\AppData\\Local\\Temp\\ipykernel_101080\\891293443.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  matches['business_id'] = matches.index.get_level_values(1)\n"
     ]
    }
   ],
   "source": [
    "matches['entity_id'] = matches.index.get_level_values(0)\n",
    "matches['business_id'] = matches.index.get_level_values(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "683556b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             entity_id  business_id  confidence_score\n",
      "7     81911          7        81911          0.812385\n",
      "      82926          7        82926          0.895760\n",
      "      84020          7        84020          0.893032\n",
      "3260  82926       3260        82926          0.809016\n",
      "      83734       3260        83734          0.808502\n",
      "...                ...          ...               ...\n",
      "94033 79875      94033        79875          0.994118\n",
      "94034 72786      94034        72786          0.967469\n",
      "94036 53965      94036        53965          0.953301\n",
      "94167 69598      94167        69598          0.960116\n",
      "94538 79362      94538        79362          0.946438\n",
      "\n",
      "[33298 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "columns=columns = ['entity_id', 'business_id', 'confidence_score']\n",
    "matched = pd.DataFrame(matches[['entity_id', 'business_id', 'confidence_score']], columns=columns)\n",
    "print(matched)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "927c2dfc",
   "metadata": {},
   "source": [
    "### Jellyfish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c0c6b4aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import jellyfish\n",
    "from src.jellyfish import clean_and_merge, calculate_similarity, find_high_confidence_matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d77e22fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the datasets\n",
    "left_dataset = pd.read_csv(left_dataset_path)\n",
    "right_dataset = pd.read_csv(right_dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7de18557",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean and merge dataset using the function\n",
    "merged_df = clean_and_merge(left_dataset, right_dataset)\n",
    "\n",
    "# Find high confidence matches with the set up of the threshold\n",
    "high_confidence_matches = find_high_confidence_matches(merged_df, threshold=0.80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ba16d86e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          entity_id  business_id  similarity_score\n",
      "424               7        36752          0.823996\n",
      "2606           2887        40775          0.976190\n",
      "2863           2887        49464          0.817110\n",
      "3462           3241        41513          0.857944\n",
      "3693           3241        49438          0.975000\n",
      "...             ...          ...               ...\n",
      "34706430      39137        48887          0.962963\n",
      "34706661      45570        51316          0.975238\n",
      "34706730      49626        48119          0.921447\n",
      "34706746      49626        49649          0.988889\n",
      "34707154      79058        49649          0.843804\n",
      "\n",
      "[25659 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "print(high_confidence_matches)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "363e1280",
   "metadata": {},
   "source": [
    "### Difflib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d28d28b",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'src.difflib'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mre\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdifflib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SequenceMatcher\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdifflib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m clean_text, standardize_zip_code, clean_address, create_enhanced_block_keys, fuzzy_match_with_difflib\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'src.difflib'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from difflib import SequenceMatcher\n",
    "from src.difflib import clean_text, standardize_zip_code, clean_address, create_enhanced_block_keys, fuzzy_match_with_difflib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f2d06c0c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'left_dataset_path' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Load the datasets\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m left_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(left_dataset_path)\n\u001b[1;32m      3\u001b[0m right_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(right_dataset_path)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'left_dataset_path' is not defined"
     ]
    }
   ],
   "source": [
    "# Load the datasets\n",
    "left_df = pd.read_csv(left_dataset_path)\n",
    "right_df = pd.read_csv(right_dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1366d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply text cleaning\n",
    "left_df['name'] = left_df['name'].apply(clean_text)\n",
    "left_df['state'] = left_df['state'].apply(clean_text)\n",
    "left_df['city'] = left_df['city'].apply(clean_text)\n",
    "right_df['name'] = right_df['name'].apply(clean_text)\n",
    "right_df['state'] = right_df['state'].apply(clean_text)\n",
    "right_df['city'] = right_df['city'].apply(clean_text)\n",
    "\n",
    "left_df['postal_code'] = left_df['postal_code'].apply(standardize_zip_code)\n",
    "right_df['zip_code'] = right_df['zip_code'].apply(standardize_zip_code)\n",
    "\n",
    "left_df['address'] = left_df['address'].apply(clean_address)\n",
    "right_df['address'] = right_df['address'].apply(clean_address)\n",
    "\n",
    "left_df.drop(columns=['categories'], inplace=True)\n",
    "right_df.drop(columns=['size'], inplace=True)\n",
    "\n",
    "left_df.rename(columns={'postal_code': 'zip_code'}, inplace=True)\n",
    "\n",
    "left_df = create_enhanced_block_keys(left_df)\n",
    "right_df = create_enhanced_block_keys(right_df)\n",
    "\n",
    "left_df['combined'] = left_df['name'].apply(clean_text) + \" \" + left_df['address'].apply(clean_address)\n",
    "right_df['combined'] = right_df['name'].apply(clean_text) + \" \" + right_df['address'].apply(clean_address)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d6e6d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute fuzzy matching\n",
    "matched_results = fuzzy_match_with_difflib(left_df, right_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ff47dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(matched_results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
